{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is my first (public) notebook of playing with pyspark\n",
    "\n",
    "The goal of this notebook is to demonstrare a simple use case of:\n",
    "1. using pyspark (python wrapper for spark) and access existing spark cluster\n",
    "2. loading data into spark\n",
    "3. accessing the data using the rdd-api, dataframe-api, and dataset-api\n",
    "4. simple data exploration\n",
    "\n",
    "I'll be using a sample of the gutenberg project - https://web.eecs.umich.edu/~lahiri/gutenberg_dataset.html\n",
    "\n",
    "#### The settings I'm using here:\n",
    "- spark: version 2.0.0\n",
    "- python: 3.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import urllib3 #ability to access data by url\n",
    "import pyspark #python wrapper for spark\n",
    "sc.stop()\n",
    "sc = pyspark.SparkContext(appName=\"spark-project\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we demonstrare a usage of the RDD API\n",
    "rdd = sc.textFile(\"s3n://ak-public-sandbox/datasets/gutenberg_dataset/1/8/*/*/*\")\n",
    "rdd.count()\n",
    "rdd.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's see some fitering capabilities\n",
    "rdd.filter(lambda line: \"mankind\" in line).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the good old word count\n",
    "counts = rdd.flatMap(lambda line: line.split(\" \")).map(lambda word: (word,1)).reduceByKey(lambda a,b: a + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some word-level stats\n",
    "from pprint import pprint\n",
    "stop_words = counts.takeOrdered(10,lambda a:-a[1])\n",
    "rare_words = counts.takeOrdered(10,lambda a:a[1])\n",
    "print(\"Stop words:\")\n",
    "pprint(stop_words)\n",
    "print(\"Rare words:\")\n",
    "pprint(rare_words)\n",
    "print(\"total number of uniqu words %s\" % counts.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd.filter(lambda line: \"mankind\" in line).saveAsTextFile(\"s3n://spark-course-data2/result/lesson_2-2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mankindLines = sc.textFile(\"s3n://spark-course-data2/result/lesson_2-2\")\n",
    "mankindLines.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = sc.wholeTextFiles(\"s3n://spark-course-data2/gutenberg_dataset/1/8/*/*/*\")\n",
    "rdd.count()\n",
    "rdd.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "session = boto3.Session() # leave out the profile_name argument if you haven't defined profiles\n",
    "s3 = boto3.resource('s3')\n",
    "bucket = s3.Bucket('spark-course-data2')\n",
    "objs = bucket.objects.filter(Prefix='gutenberg_dataset/1')\n",
    "for obj in objs:  \n",
    "  print(obj.key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = s3.Object('spark-course-data2', 'gutenberg_dataset/1/9/9/1997/1997.txt')\n",
    "content = obj.get()[\"Body\"].read().decode(\"utf-8\")\n",
    "print(content[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "http = urllib3.PoolManager()\n",
    "r = http.request('GET', 'https://www.kaggle.com/c/titanic/download/train.csv')\n",
    "r.status\n",
    "#response = urllib3.urlopen('')\n",
    "#html = response.read()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
